# -*- coding: utf-8 -*-
"""ClipScore_final_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jIG-vM2MsOv3j-_kU1AkHknZokyJv7ki
"""

!pip install torch torchvision -q
!pip install ftfy regex -q
!pip install git+https://github.com/openai/CLIP.git -q
!apt install wget -q

# Function to recursively extract comments
def extract_comments(comment, all_comments):
    all_comments.append(comment["body"])
    if "replies" in comment:
        for reply in comment["replies"]:
            extract_comments(reply, all_comments)



# Function to recursively extract comments
def extract_image_link(comment, all_images):
    if  "image_link" in  comment:
        all_images.append(comment["image_link"])
    if "replies" in comment:
        for reply in comment["replies"]:
            extract_image_link(reply, all_images)

import os
import gdown

def download_images_to_folder(image_links, folder_path):

    # Create folder if it doesn't exist
    os.makedirs(folder_path, exist_ok=True)

    # List to store paths of downloaded images
    downloaded_image_paths = []

    # Download each image
    for image_link in image_links:
        # Extract the file ID from the shareable link
        file_id = image_link.split('/')[-2]

        # Download the file
        destination_path = os.path.join(folder_path, f"image_{file_id}.jpg")
        gdown.download(f'https://drive.google.com/uc?id={file_id}', destination_path, quiet=False)

        # Add the path to the list of downloaded images
        downloaded_image_paths.append(destination_path)

    return downloaded_image_paths


# Function to calculate CLIP score
def calculate_clip_score(image, comment):
    with torch.no_grad():
        image_input = preprocess(Image.open(image)).unsqueeze(0).to(device)
        comment_input = clip.tokenize([comment]).to(device)

        image_features = model.encode_image(image_input)
        comment_features = model.encode_text(comment_input)

        clip_score = (100 * image_features @ comment_features.T).softmax(dim=-1)

    return clip_score.item()

!rm -rf /content/images

import torch
import clip
from PIL import Image
import matplotlib.pyplot as plt
import json
import os

# Load the CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# Function to download images from URLs
def download_images(image_urls, download_dir):
    os.makedirs(download_dir, exist_ok=True)
    for i, url in enumerate(image_urls):
        filename = os.path.join(download_dir, f"image_{i}.jpg")
        !wget -q -O {filename} {url}
    return [os.path.join(download_dir, f"image_{i}.jpg") for i in range(len(image_urls))]

# Load the JSON dataset
def load_dataset(json_file):
    with open(json_file, 'r') as f:
        data = json.load(f)
    return data

# Define your dataset file
json_file = "Path to Dataset"

# Load dataset
dataset = load_dataset(json_file)

for post_number in range(1):
  post_comments = []
  image_links_cmt = []
  for comments in dataset[post_number]['comments']:
    extract_comments(comments, post_comments)
    extract_image_link(comments,image_links_cmt)


# Extract images URLs and comments from the dataset
image_urls = []
comments = [ ]
comments += post_comments
# Download images
download_dir = "images"
image_paths = download_images(image_urls, download_dir)
image_paths += download_images_to_folder(image_links_cmt, download_dir)


# Calculate clip score for each image-comment pair
clip_scores = {}
for image_path in image_paths:
    clip_scores[image_path] = []
    for comment in comments:
        score = calculate_clip_score(image_path, comment)
        clip_scores[image_path].append(score)

# Calculate the summation of clip scores for each image
summation_scores = {}
for image_path, scores in clip_scores.items():
    summation_scores[image_path] = sum(scores)

# Determine the image with the highest summation of clip scores
chosen_image = max(summation_scores, key=summation_scores.get)



# Print the final chosen image
print(f"The final chosen image is: {chosen_image}")

# Display the final chosen image
plt.imshow(Image.open(chosen_image))
plt.axis('off')
plt.show()

image_urls

from google.colab import drive
drive.mount('/content/drive')

[1]+[2]

